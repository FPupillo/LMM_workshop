PEmean = 0.30,# PEmean
beta_PE = 1.28, # effect of PE (fixed slope)
n_items = 300, # number of trials
tau_0 = 1.80, # by-subject random intercept sd .Check if it is sd, because than it will be squared into variance
tau_1 = 2.50, # by-subject random slope sd
rho = 0.3, # correlation between intercept and slope
sigma = 0.3, # residual standard deviation
RTorACC = 1 # Reaction times or accuracy (1 = RT, 2 = accuracy)
)
write(df, "mydata.csv")
View(df)
write.csv(df, "mydata.csv")
knitr::opts_chunk$set(echo = TRUE)
set.seed(1234)
df<-my_sim_data(
SubN = 30,
beta_0 = 0.60, # grand mean (fixed intercept)
PEmean = 0.30,# PEmean
beta_PE = 1.28, # effect of PE (fixed slope)
n_items = 300, # number of trials
tau_0 = 1.80, # by-subject random intercept sd .Check if it is sd, because than it will be squared into variance
tau_1 = 2.50, # by-subject random slope sd
rho = 0.3, # correlation between intercept and slope
sigma = 0.3, # residual standard deviation
RTorACC = 2 # Reaction times or accuracy (1 = RT, 2 = accuracy)
)
# load the packages and source functions
library(dplyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(RLRsim)
source("helper_functions/simulateData.R")
# suppress scientific notation
options(scipen=5)
set.seed(1234)
df<-my_sim_data(
SubN = 30,
beta_0 = 0.60, # grand mean (fixed intercept)
PEmean = 0.30,# PEmean
beta_PE = 1.28, # effect of PE (fixed slope)
n_items = 300, # number of trials
tau_0 = 1.80, # by-subject random intercept sd .Check if it is sd, because than it will be squared into variance
tau_1 = 2.50, # by-subject random slope sd
rho = 0.3, # correlation between intercept and slope
sigma = 0.3, # residual standard deviation
RTorACC = 2 # Reaction times or accuracy (1 = RT, 2 = accuracy)
)
# show first row of simulated data
head(df)
write.csv(df, "mydata.csv")
knitr::opts_chunk$set(echo = TRUE)
# load the packages and source functions
library(dplyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(RLRsim)
source("helper_functions/simulateData.R")
# suppress scientific notation
options(scipen=5)
# set.seed
set.seed(1234)
df<-my_sim_data(
SubN = 30,
beta_0 = 0.60, # grand mean (fixed intercept)
PEmean = 0.30,# PEmean
beta_PE = 1.28, # effect of PE (fixed slope)
n_items = 300, # number of trials
tau_0 = 1.80, # by-subject random intercept sd .Check if it is sd, because than it will be squared into variance
tau_1 = 2.50, # by-subject random slope sd
rho = 0.3, # correlation between intercept and slope
sigma = 0.3, # residual standard deviation
RTorACC = 1 # Reaction times or accuracy (1 = RT, 2 = accuracy)
)
# show first row of simulated data
head(df)
# We are assuming that RT are normally distributed
# aggregate RT at the subject level
df_agg<-df %>%
group_by(subj_id) %>%
summarise(RT=mean(RT), PE=mean(PE))
# plot
ggplot(df_agg, aes(y=RT, x = PE))+
geom_point()+
geom_smooth(method="lm")
# simple regression
linearmod<-lm(RT~PE, data = df_agg)
# get the summary
summary(linearmod)
# first, let's run an intercept only, unconditional model
mixmod_unc<-lmer(RT~1+(1|subj_id), data = df, control=lmerControl(optimizer="bobyqa"))#,optCtrl=list(maxfun=100000)))
summary(mixmod_unc)
# calculate the intraclass correlation
ICC<-VarCorr(mixmod_unc)$subj_id[1]/(VarCorr(mixmod_unc)$subj_id[1]+summary(mixmod_unc)$sigma^2)
# paste the results
paste("The IntraClass Correlation is",  ICC)
# test significance
# model without random intercept. We can create a random intercept that is constant at 1
df$constint<-rep(1, nrow(df))
mod_unc<-lm(RT~1, data=df)
mixmod_unc<-lmer(RT~1+(1|subj_id), data = df)
anova(mixmod_unc, mod_unc)
# use simulation based-test
exactLRT(mixmod_unc,mod_unc)
# plot
ggplot(df, aes(y=RT, x = PE))+
geom_line(stat="smooth", method= "lm", formula = y~x, alpha = 0.5)+aes(colour = factor(subj_id))+
geom_smooth(method="lm", colour="black")
maxMod<-lmer(RT~PE+(1+PE|subj_id), data = df, control=lmerControl(optimizer="bobyqa"))
summary(maxMod)
anova(maxMod)
# grand mean centring and person mean centring
df<- df %>%
# Grand mean centering (GMC)
mutate (PE.gmc = PE-mean(PE)) %>%
# Person mean centering (centering withing clusters - Participants)
group_by(subj_id) %>%
mutate(PE.cm = mean(PE),
PE.cwc = PE-PE.cm ) %>%
ungroup %>%
# grand mean centering of the aggregated variable
mutate(PE.cmc= PE.cm-mean(PE.cm))
maxModCent<-lmer(RT~PE.cwc+PE.cmc+(1+PE.cwc|subj_id), data = df, control=lmerControl(optimizer="bobyqa"))
summary(maxModCent)
## R^2pseudo:within
# we create a new model including PE grand mean centered (PE_gmc) as preditor for RT
ModPE<-lmer(RT~PE.gmc+(1|subj_id), data = df, control=lmerControl(optimizer="bobyqa"))
summary(ModPE)
# used to quantify the change in (within) residual variance
# variance residuum m0 - variance residuum m1 / variance residuum m0 = 1- Variance residuum m1/variance residuum m0
1 - summary(ModPE)$sigma^2/summary(mixmod_unc)$sigma^2
## R^2pseudo:between
# Variance Intercept modunc - Variance ModPE/Variance mixmod_unc = 1-Variance ModPE/Variance mixmod_unc
1 - VarCorr(ModPE)$subj_id[1]/VarCorr(mixmod_unc)$subj_id[1]
## R^2pseudo:bw (between and within)
# explained variance of each model = variance intercept + residual variance
# R^2pseudo:bw = 1-(Var.intercept ModPE + Var.residuum ModPE)/(Var. intercept mixedmod_unc + Var. Residuum mixedmod_unc)
1 - (VarCorr(ModPE)$subj_id[1] + summary(ModPE)$sigma^2)/(VarCorr(mixmod_unc)$subj_id[1] + summary(mixmod_unc)$sigma^2)
## if we want to include random slopes, we need to consider these sources of variances as well in our calculation
# fit a model with covariance of random effects set at zero
maxModZeroCov<-lmer(RT~PE+PE+(PE||subj_id), data = df, control=lmerControl(optimizer="bobyqa"))
summary(maxModZeroCov)
# let's compare
anova(maxMod, maxModZeroCov )
# first shuffle the items
# baseline model
m0 <-lm(RT~PE+PE, data = df)
# add random effect
m1 <-lmer(RT~PE+(1|subj_id), data = df)
anova(m1, m0)
m2<- lmer(RT~PE+(1|subj_id) + (1|item_id), data = df)
summary(m2)
m3<-  lmer(RT~PE+(1+PE||subj_id), data = df)
anova(m3, m1)
m4<-  lmer(RT~PE+(1+PE|subj_id), data = df)
anova(m4, m3)
# make it more complex
# m2 <-
# create a categorical predictor between, simulating that we are randomly assigning participants
# to different groups of PE
PEbet<-rep(c("HighPE", "LowPE", "MediumPE"), each= nrow(df_agg)/3)
# created the levels in the aggregated dataset
# pick random subject
set.seed(1234)
df_agg$PEbw<-sample(PEbet, nrow(df_agg), replace = F)
# we want it as factor
df_agg$PEbw<-as.factor(df_agg$PEbw)
# descriptives
df_agg %>%
group_by(PEbw) %>%
summarise(mean=mean(RT), sd = sd(RT))
# plot
ggplot(df_agg, aes(PEbw, RT))+
geom_bar(aes(PEbw, RT, fill = PEbw),
position="dodge",stat="summary")+
geom_point()+
stat_summary(fun.data = "mean_cl_boot", size = 0.8, geom="errorbar", width=0.2 )# this line adds error bars
# create an Anova between participant
bwlm<-lm(RT~PEbw, data=df_agg)
summary(bwlm)
# re-level in order to have medium as the reference level
df_agg$PEbw<-relevel(df_agg$PEbw, ref = "MediumPE")
# refit
bwlm<-lm(RT~PEbw, data=df_agg)
summary(bwlm)
anova(bwlm)
# method 1: contrast poly
contrasts(df_agg$PEbw)<-contr.poly(3) # we have three levels in our categorical predictor
# refit the model
bwlmContr<-lm(RT~PEbw, data=df_agg)
summary(bwlmContr)
# set our own contrasts
# linear
contrast1<-c(-1,0,1)
# quadratic
contrast2<-c(1,-2,1)
contrasts(df_agg$PEbw)<-cbind(contrast1, contrast2)
# refit the model
bwlmContrCust<-lm(RT~PEbw, data=df_agg)
summary(bwlmContrCust)
# what if we convert the categorical into continuous?
df_agg$PEbwC<-as.vector(NA)
for (n in 1:nrow(df_agg)){
if (df_agg$PEbw[n]=="MediumPE"){
df_agg$PEbwC[n]<-0.33
} else if (df_agg$PEbw[n] == "HighPE"){
df_agg$PEbwC[n]<-0.80
}  else if (df_agg$PEbw[n] == "LowPE"){
df_agg$PEbwC[n]<-0.20
}
}
ggplot(df_agg, aes(y=RT, x = PEbwC))+
geom_point()+
geom_smooth(method="lm")
# fit lm
bwlmC<-lm(RT~PEbwC, data=df_agg)
summary(bwlmC)
# we have a categorical variable in the dataset, which is PElevel
df$PElevel<-as.factor(df$PElevel)
# let's inspect that
ggplot(df, aes(y=RT, x = PElevel))+
geom_boxplot( )
# eazy anova on the aggregate dataset
df_aggbw<-df %>%
group_by(subj_id,PElevel) %>%
summarise(RT=mean(RT))
head(df_aggbw)
# ezanova
library(ez)
ezModel<-ezANOVA(data = df_aggbw, # dataframe
dv = .(RT), # dependent variable. This functions requires to place the name of each variable within .()
wid = .(subj_id), # variable that identifies participants )
within = .(PElevel), # independent variable
detailed = T
)
ezModel
#
ModCateg<-lmer(RT~PElevel+(PElevel|subj_id), data = df, control=lmerControl(optimizer="bobyqa"))
summary(ModCateg)
# try nlme
library(nlme)
test.lme<-lme(fixed = RT~PElevel,
random = ~ PElevel| subj_id,
data = df,
method = "REML",
control= lmeControl( opt = "optim", optimMethod ="BFGS" ))
summary(test.lme)
test.lme
# now model with continuous predictor
# what if we convert the categorical into continuous?
df$PEbwC<-as.vector(NA)
for (n in 1:nrow(df)){
if (df$PElevel[n]==2){
df$PEbwC[n]<-0.33
} else if (df$PElevel[n] == 3){
df$PEbwC[n]<-0.80
}  else if (df$PElevel[n] == 1){
df$PEbwC[n]<-0.20
}
}
# contr. poly
# custom contrast
set.seed(1234)
df_acc<-my_sim_data(
SubN = 30,
beta_0 = 0.60, # grand mean (fixed intercept)
PEmean = 0.30,# PEmean
beta_PE = 1.28, # effect of PE (fixed slope)
n_items = 300, # number of trials
tau_0 = 1.80, # by-subject random intercept sd .Check if it is sd, because than it will be squared into variance
tau_1 = 2.50, # by-subject random slope sd
rho = 0.3, # correlation between intercept and slope
sigma = 0.2, # residual standard deviation
RTorACC = 2 # Reaction times or accuracy (1 = RT, 2 = accuracy)
)
# show first row of simulated data
head(df_acc)
logmod<-glm(rec_acc~PE, data = df_acc, family = binomial)
summary(logmod)
# take the exponential of the coefficients to get the ODDS
OR <- exp(logmod$coefficients)
# calculate confidence intervals for the odds ratio
exp(confint(logmod))
# first, visualize the data
ggplot(df_acc, aes(rec_acc, x = PE))+
geom_line(stat="smooth", method= "glm", formula = y~x,method.args=list(family="binomial"), alpha = 0.5)+
aes(colour = factor(subj_id))+
geom_smooth(method="glm", method.args=list(family="binomial"),colour="black")
GLMMmod<-glmer(rec_acc~PE+(PE|subj_id), data = df_acc, family = binomial)
GLMMmodsum<-summary(GLMMmod)
GLMMmodsum
# take the exponential of the coefficients to get the ODDS
OR <- exp(GLMMmodsum$coefficients)
# calculate confidence intervals for the odds ratio
# Attention: it takes a long time to estimate!
# exp(confint(GLMMmod))
# model
GLMMmodCat<-glmer(rec_acc~PElevel+(PElevel|subj_id), data = df_acc, family = binomial)
# model
GLMMmodCat<-glmer(rec_acc~PElevel+(PElevel|subj_id), data = df_acc, family = binomial)
summary(GLMMmodCat)
# convert PElevel to a factor
df_acc$PElevel<-as.factor(df_acc$PElevel)
# model
GLMMmodCat<-glmer(rec_acc~PElevel+(PElevel|subj_id), data = df_acc, family = binomial)
summary(GLMMmodCat)
anova(GLMMmodCat)
anova(bwlmC)
anova(bwlmContrCust)
anova(ModCateg)
?anova
anova(ModCateg, type = "I")
anova(ModCateg, type = "IV")
anova(ModCateg, type = "III")
library(lmerTest)
anova(GLMMmodCat)
lmerTest::anova(GLMMmodCat)
lmerTest::Anova(GLMMmodCat)
library(afex)
install.packages("afex")
?mixed
library(afex)
library(mixed)
mixed(GLMMmodCat)
mixed(rec_acc~PElevel+(PElevel|subj_id),
data=df_acc)
mixed(rec_acc~PElevel+(PElevel|subj_id),family = binomial,
data=df_acc, args.test=list(nsim=3))
mixed(rec_acc~PElevel+(PElevel|subj_id),family = binomial,
data=df_acc)
mixed(rec_acc~PElevel+(PElevel|subj_id),family = binomial,method = "PB",
data=df_acc)
knitr::opts_chunk$set(echo = TRUE)
# load the packages and source functions
library(dplyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(RLRsim)
source("helper_functions/simulateData.R")
# suppress scientific notation
options(scipen=5)
# set.seed
set.seed(1234)
df<-my_sim_data(
SubN = 30,
beta_0 = 0.60, # grand mean (fixed intercept)
PEmean = 0.30,# PEmean
beta_PE = 1.28, # effect of PE (fixed slope)
n_items = 300, # number of trials
tau_0 = 1.80, # by-subject random intercept sd .Check if it is sd, because than it will be squared into variance
tau_1 = 2.50, # by-subject random slope sd
rho = 0.3, # correlation between intercept and slope
sigma = 0.3, # residual standard deviation
RTorACC = 1 # Reaction times or accuracy (1 = RT, 2 = accuracy)
)
# show first row of simulated data
head(df)
# We are assuming that RT are normally distributed
# aggregate RT at the subject level
df_agg<-df %>%
group_by(subj_id) %>%
summarise(RT=mean(RT), PE=mean(PE))
# plot
ggplot(df_agg, aes(y=RT, x = PE))+
geom_point()+
geom_smooth(method="lm")
# simple regression
linearmod<-lm(RT~PE, data = df_agg)
# get the summary
summary(linearmod)
# first, let's run an intercept only, unconditional model
mixmod_unc<-lmer(RT~1+(1|subj_id), data = df, control=lmerControl(optimizer="bobyqa"))#,optCtrl=list(maxfun=100000)))
summary(mixmod_unc)
# calculate the intraclass correlation
ICC<-VarCorr(mixmod_unc)$subj_id[1]/(VarCorr(mixmod_unc)$subj_id[1]+summary(mixmod_unc)$sigma^2)
# paste the results
paste("The IntraClass Correlation is",  ICC)
# test significance
# model without random intercept. We can create a random intercept that is constant at 1
df$constint<-rep(1, nrow(df))
mod_unc<-lm(RT~1, data=df)
mixmod_unc<-lmer(RT~1+(1|subj_id), data = df)
anova(mixmod_unc, mod_unc)
# use simulation based-test
exactLRT(mixmod_unc,mod_unc)
# plot
ggplot(df, aes(y=RT, x = PE))+
geom_line(stat="smooth", method= "lm", formula = y~x, alpha = 0.5)+aes(colour = factor(subj_id))+
geom_smooth(method="lm", colour="black")
maxMod<-lmer(RT~PE+(1+PE|subj_id), data = df, control=lmerControl(optimizer="bobyqa"))
summary(maxMod)
anova(maxMod)
# grand mean centring and person mean centring
df<- df %>%
# Grand mean centering (GMC)
mutate (PE.gmc = PE-mean(PE)) %>%
# Person mean centering (centering withing clusters - Participants)
group_by(subj_id) %>%
mutate(PE.cm = mean(PE),
PE.cwc = PE-PE.cm ) %>%
ungroup %>%
# grand mean centering of the aggregated variable
mutate(PE.cmc= PE.cm-mean(PE.cm))
maxModCent<-lmer(RT~PE.cwc+PE.cmc+(1+PE.cwc|subj_id), data = df, control=lmerControl(optimizer="bobyqa"))
summary(maxModCent)
## R^2pseudo:within
# we create a new model including PE grand mean centered (PE_gmc) as preditor for RT
ModPE<-lmer(RT~PE.gmc+(1|subj_id), data = df, control=lmerControl(optimizer="bobyqa"))
summary(ModPE)
# used to quantify the change in (within) residual variance
# variance residuum m0 - variance residuum m1 / variance residuum m0 = 1- Variance residuum m1/variance residuum m0
1 - summary(ModPE)$sigma^2/summary(mixmod_unc)$sigma^2
## R^2pseudo:between
# Variance Intercept modunc - Variance ModPE/Variance mixmod_unc = 1-Variance ModPE/Variance mixmod_unc
1 - VarCorr(ModPE)$subj_id[1]/VarCorr(mixmod_unc)$subj_id[1]
## R^2pseudo:bw (between and within)
# explained variance of each model = variance intercept + residual variance
# R^2pseudo:bw = 1-(Var.intercept ModPE + Var.residuum ModPE)/(Var. intercept mixedmod_unc + Var. Residuum mixedmod_unc)
1 - (VarCorr(ModPE)$subj_id[1] + summary(ModPE)$sigma^2)/(VarCorr(mixmod_unc)$subj_id[1] + summary(mixmod_unc)$sigma^2)
## if we want to include random slopes, we need to consider these sources of variances as well in our calculation
# fit a model with covariance of random effects set at zero
maxModZeroCov<-lmer(RT~PE+PE+(PE||subj_id), data = df, control=lmerControl(optimizer="bobyqa"))
summary(maxModZeroCov)
# let's compare
anova(maxMod, maxModZeroCov )
# baseline model
# m0 <-
# random effects
# m1 <-
# make it more complex
# m2 <-
# create a categorical predictor between, simulating that we are randomly assigning participants
# to different groups of PE
PEbet<-rep(c("HighPE", "LowPE", "MediumPE"), each= nrow(df_agg)/3)
# created the levels in the aggregated dataset
# pick random subject
set.seed(1234)
df_agg$PEbw<-sample(PEbet, nrow(df_agg), replace = F)
# we want it as factor
df_agg$PEbw<-as.factor(df_agg$PEbw)
# descriptives
df_agg %>%
group_by(PEbw) %>%
summarise(mean=mean(RT), sd = sd(RT))
# plot
ggplot(df_agg, aes(PEbw, RT))+
geom_bar(aes(PEbw, RT, fill = PEbw),
position="dodge",stat="summary")+
geom_point()+
stat_summary(fun.data = "mean_cl_boot", size = 0.8, geom="errorbar", width=0.2 )# this line adds error bars
# create an Anova between participant
bwlm<-lm(RT~PEbw, data=df_agg)
summary(bwlm)
# re-level in order to have medium as the reference level
df_agg$PEbw<-relevel(df_agg$PEbw, ref = "MediumPE")
# refit
bwlm<-lm(RT~PEbw, data=df_agg)
summary(bwlm)
anova(bwlm)
# method 1: contrast poly
contrasts(df_agg$PEbw)<-contr.poly(3) # we have three levels in our categorical predictor
# refit the model
bwlmContr<-lm(RT~PEbw, data=df_agg)
summary(bwlmContr)
# set our own contrasts
# linear
contrast1<-c(-1,0,1)
# quadratic
contrast2<-c(1,-2,1)
contrasts(df_agg$PEbw)<-cbind(contrast1, contrast2)
# refit the model
bwlmContrCust<-lm(RT~PEbw, data=df_agg)
summary(bwlmContrCust)
# what if we convert the categorical into continuous?
df_agg$PEbwC<-as.vector(NA)
for (n in 1:nrow(df_agg)){
if (df_agg$PEbw[n]=="MediumPE"){
df_agg$PEbwC[n]<-0.33
} else if (df_agg$PEbw[n] == "HighPE"){
df_agg$PEbwC[n]<-0.80
}  else if (df_agg$PEbw[n] == "LowPE"){
df_agg$PEbwC[n]<-0.20
}
}
ggplot(df_agg, aes(y=RT, x = PEbwC))+
geom_point()+
geom_smooth(method="lm")
# fit lm
bwlmC<-lm(RT~PEbwC, data=df_agg)
summary(bwlmC)
# we have a categorical variable in the dataset, which is PElevel
df$PElevel<-as.factor(df$PElevel)
# let's inspect that
ggplot(df, aes(y=RT, x = PElevel))+
geom_boxplot( )
# eazy anova on the aggregate dataset
df_aggbw<-df %>%
group_by(subj_id,PElevel) %>%
summarise(RT=mean(RT))
head(df_aggbw)
# ezanova
library(ez)
ezModel<-ezANOVA(data = df_aggbw, # dataframe
dv = .(RT), # dependent variable. This functions requires to place the name of each variable within .()
wid = .(subj_id), # variable that identifies participants )
within = .(PElevel), # independent variable
detailed = T
)
ezModel
View(df)
